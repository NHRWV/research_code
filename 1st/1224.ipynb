{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5aa8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "491d3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = pd.read_excel('all_df.xlsx')\n",
    "before_covid_umap_df = pd.read_excel('before_covid_umap_df(20) (2).xlsx')\n",
    "covid_umap_df = pd.read_excel('covid_umap_df(20) (2).xlsx')\n",
    "after_covid_umap_df = pd.read_excel('after_covid_umap_df(20) (2).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93990204",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e576071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_template = \"\"\"The following is a set of documents\n",
    "# {docs}\n",
    "# Based on this list of docs, please identify the main themes in Korean.\n",
    "# Helpful Answer:\"\"\"\n",
    "\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, you should identify the main themes in Korean.\n",
    "Instead of simply listing the content, please provide the overarching themes based on the technologies and fields that run through each docs.\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    template=map_template\n",
    ")\n",
    "\n",
    "map_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e9032aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce_template = \"\"\"The following is set of summaries in Korean:\n",
    "# {docs}\n",
    "# Take these and distill it into a final, consolidated summary of the main themes in 500 characters or less in Korean. \n",
    "# Helpful Answer:\"\"\"\n",
    "\n",
    "reduce_template = \"\"\"The following is set of summaries in Korean:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary of the main themes three sentences or less in Korean. \n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a184709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain\n",
    "    # The maximum number of tokens to group documents into.\n",
    "#    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84b318d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8e641ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    add_start_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9aa42007",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up_lst2 = [[], [], []] # 프롬프트\n",
    "\n",
    "df_lst = [before_covid_umap_df, covid_umap_df, after_covid_umap_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30cd042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(df_lst):\n",
    "    cluster_num = 0\n",
    "    \n",
    "    while cluster_num in i['cluster'].values:\n",
    "        cluster = list(i.loc[i['cluster'] == cluster_num, '초록(국문)'])\n",
    "        split_docs = text_splitter.create_documents(cluster)\n",
    "\n",
    "        result = map_reduce_chain.run(split_docs)    \n",
    "        sum_up_lst2[idx].append(result)\n",
    "        \n",
    "        cluster_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f38cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up_lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775736af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up_lst2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f67ab187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'주어진 문서를 기반으로 한국어의 주요 테마는 다음과 같습니다:\\n\\n1. 고부가 신규상품 개발에 따른 브랜드인지도 향상\\n2. 총생산(GRDP) 증대\\n3. 창업 및 기존 기업의 매출증대로 인해 총생산 증대\\n4. 3차 산업의 활성화 토대\\n5. 역내 제품 고부가가치화를 통한 고급시장 선점 확대\\n6. 창업 기업 증가로 인한 고용 및 세수 증대\\n7. 지역 인견 산업의 세계적 명품화에 따른 인구유입증가 효과\\n\\n이를 요약하면 다음과 같습니다:\\n고부가 신규상품 개발을 통한 브랜드인지도 향상, 총생산 증대, 창업 및 기업 매출증대로 인한 총생산 증대, 3차 산업 활성화, 역내 제품 고부가가치화를 통한 고급시장 선점 확대, 창업 기업 증가로 인한 고용 및 세수 증대, 지역 인견 산업의 세계적 명품화에 따른 인구유입증가 효과.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_up_lst2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up_lst2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_up_lst2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017444a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
